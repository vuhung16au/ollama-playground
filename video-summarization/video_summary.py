import os
import logging
import time
import json
from datetime import datetime

import cv2
import streamlit as st
from langchain_ollama.llms import OllamaLLM

# Configure Streamlit page
st.set_page_config(
    page_title="Video Summarization App",
    page_icon="üìπ",
    layout="wide",
    initial_sidebar_state="expanded"
)

videos_directory = 'videos/'
frames_directory = 'frames/'
logs_directory = 'logs/'

# Configure logging
os.makedirs(logs_directory, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(funcName)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(logs_directory, 'video_summary.log')),
        logging.StreamHandler()  # Also log to console
    ]
)
logger = logging.getLogger(__name__)

# Sidebar Configuration
st.sidebar.title("‚öôÔ∏è Settings")

# Frame extraction settings
st.sidebar.subheader("Frame Extraction")
interval_seconds = st.sidebar.slider("Frame Interval (seconds)", 1, 30, 5)
max_frames = st.sidebar.slider("Max Frames", 5, 50, 20)

# Model settings
st.sidebar.subheader("AI Model")
available_models = ["gemma3:27b", "llava:7b", "bakllava"]
selected_model = st.sidebar.selectbox("Select Model", available_models, index=0)

# Summary settings
st.sidebar.subheader("Summary Options")
summary_length = st.sidebar.radio("Summary Length", ["Brief", "Detailed", "Comprehensive"])
include_timestamps = st.sidebar.checkbox("Include Timestamps", value=False)

model = OllamaLLM(model=selected_model)

# Log application startup
logger.info("Video Summarization Application Started")
logger.info(f"Configured directories - Videos: {videos_directory}, Frames: {frames_directory}, Logs: {logs_directory}")
logger.info(f"Using model: {selected_model}")

def save_processing_history(video_name, summary, processing_time, model_used):
    """Save processing history to JSON file."""
    history_file = "processing_history.json"
    
    entry = {
        "timestamp": datetime.now().isoformat(),
        "video_name": video_name,
        "summary": summary,
        "processing_time": processing_time,
        "model_used": model_used
    }
    
    if os.path.exists(history_file):
        with open(history_file, 'r') as f:
            history = json.load(f)
    else:
        history = []
    
    history.append(entry)
    
    # Keep only last 50 entries
    history = history[-50:]
    
    with open(history_file, 'w') as f:
        json.dump(history, f, indent=2)

def export_summary(summary, video_name, processing_time, model_used):
    """Create exportable summary report."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    report = f"""# Video Summary Report

**Video:** {video_name}
**Generated:** {timestamp}
**Processing Time:** {processing_time:.2f} seconds
**Model Used:** {model_used}

## Summary
{summary}

---
Generated by Video Summarization App
"""
    return report

def display_extracted_frames():
    """Display thumbnails of extracted frames."""
    if os.path.exists(frames_directory):
        frame_files = sorted([f for f in os.listdir(frames_directory) if f.endswith('.jpg')])
        
        if frame_files:
            st.markdown("### üñºÔ∏è Extracted Frames")
            cols = st.columns(min(len(frame_files), 4))
            
            for i, frame_file in enumerate(frame_files[:8]):  # Show max 8 frames
                with cols[i % 4]:
                    frame_path = os.path.join(frames_directory, frame_file)
                    st.image(frame_path, caption=f"Frame {i+1}", use_container_width=True)

def display_processing_history():
    """Display recent processing history in sidebar."""
    st.sidebar.subheader("üìä Recent Summaries")
    if os.path.exists("processing_history.json"):
        with open("processing_history.json", 'r') as f:
            history = json.load(f)
        
        if history:
            for entry in reversed(history[-5:]):  # Show last 5, most recent first
                with st.sidebar.expander(f"{entry['video_name'][:15]}..."):
                    st.write(f"**Date:** {entry['timestamp'][:10]}")
                    st.write(f"**Time:** {entry['processing_time']:.1f}s")
                    st.write(f"**Model:** {entry.get('model_used', 'N/A')}")
                    st.write(f"**Summary:** {entry['summary'][:100]}...")
    else:
        st.sidebar.info("No processing history yet.")

def get_summary_prompt(length, include_timestamps):
    """Generate summary prompt based on user preferences."""
    base_prompt = "Analyze the video content from these frames and provide"
    
    if length == "Brief":
        prompt = f"{base_prompt} a concise 2-3 sentence summary."
    elif length == "Detailed":
        prompt = f"{base_prompt} a detailed paragraph summary covering the main content and key visual elements."
    else:  # Comprehensive
        prompt = f"{base_prompt} a comprehensive summary including scene descriptions, activities, objects, and overall narrative."
    
    if include_timestamps:
        prompt += " Include approximate timestamps or sequence information where relevant."
    
    return prompt

def upload_video(file):
    """Upload video file to videos directory."""
    logger.info(f"Starting video upload for file: {file.name}")
    start_time = time.time()
    
    # Ensure videos directory exists
    os.makedirs(videos_directory, exist_ok=True)
    
    file_path = videos_directory + file.name
    try:
        with open(file_path, "wb") as f:
            f.write(file.getbuffer())
        
        end_time = time.time()
        duration = end_time - start_time
        logger.info(f"Video upload completed successfully. Duration: {duration:.2f} seconds")
        st.success(f"Video uploaded: {file.name}")
        return file_path
    except Exception as e:
        logger.error(f"Failed to upload video {file.name}: {str(e)}")
        raise

def extract_frames(video_path, interval_seconds=5):
    """Extract frames from video at specified intervals."""
    logger.info(f"Starting frame extraction from video: {video_path}")
    start_time = time.time()
    
    # Clear existing frames
    if os.path.exists(frames_directory):
        frame_files = os.listdir(frames_directory)
        for file in frame_files:
            os.remove(frames_directory + file)
        logger.info(f"Cleared {len(frame_files)} existing frames")
    else:
        os.makedirs(frames_directory, exist_ok=True)

    video = cv2.VideoCapture(video_path)
    
    if not video.isOpened():
        logger.error(f"Could not open video file: {video_path}")
        st.error(f"Error: Could not open video file {video_path}")
        return

    fps = video.get(cv2.CAP_PROP_FPS)
    frames_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if fps <= 0:
        logger.error("Could not determine video FPS")
        st.error("Error: Could not determine video FPS")
        video.release()
        return
        
    fps = int(fps)
    video_duration = frames_count / fps
    logger.info(f"Video info: {frames_count} frames, {fps} FPS, {video_duration:.2f} seconds duration")
    st.info(f"Video info: {frames_count} frames, {fps} FPS")

    # Add progress tracking
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    current_frame = 0
    frame_number = 1
    frames_extracted = 0
    max_possible_frames = min(frames_count // (fps * interval_seconds), max_frames)

    while current_frame < frames_count and frames_extracted < max_frames:
        # Update progress
        progress = min(current_frame / frames_count, 1.0)
        progress_bar.progress(progress)
        status_text.text(f"Extracting frames... {frames_extracted}/{max_possible_frames}")
        
        video.set(cv2.CAP_PROP_POS_FRAMES, current_frame)
        success, frame = video.read()

        if not success:
            logger.warning(f"Failed to read frame at position {current_frame}")
            current_frame += fps * interval_seconds
            continue

        if frame is not None and frame.size > 0:
            frame_path = frames_directory + f"frame_{frame_number:03d}.jpg"
            cv2.imwrite(frame_path, frame)
            frames_extracted += 1
            logger.debug(f"Extracted frame {frame_number} at time {current_frame/fps:.2f}s")

        current_frame += fps * interval_seconds
        frame_number += 1
        
        # Safety break to avoid infinite loops
        if frame_number > 100:  # Max 100 frames
            logger.warning("Reached maximum frame limit (100), stopping extraction")
            break

    video.release()
    progress_bar.progress(1.0)
    status_text.text("Frame extraction completed!")
    
    end_time = time.time()
    duration = end_time - start_time
    logger.info(f"Frame extraction completed. Extracted {frames_extracted} frames in {duration:.2f} seconds")
    st.success(f"Extracted {frames_extracted} frames from video")

def describe_video():
    """Analyze extracted frames and generate video summary."""
    logger.info("Starting video content analysis")
    start_time = time.time()
    
    if not os.path.exists(frames_directory):
        logger.error("Frames directory not found")
        st.error("No frames directory found")
        return "Error: No frames extracted"
        
    frame_files = [f for f in os.listdir(frames_directory) if f.endswith('.jpg')]
    
    if not frame_files:
        logger.error("No frame files found for analysis")
        st.error("No frames found for analysis")
        return "Error: No frames to analyze"
    
    images = []
    for file in sorted(frame_files):  # Sort to ensure consistent ordering
        images.append(os.path.join(frames_directory, file))

    logger.info(f"Found {len(images)} frames for analysis")
    st.info(f"Analyzing {len(images)} frames...")
    
    try:
        model_with_images = model.bind(images=images)
        logger.info("Invoking AI model for video summarization")
        model_start_time = time.time()
        
        # Use custom prompt based on user preferences
        custom_prompt = get_summary_prompt(summary_length, include_timestamps)
        summary = model_with_images.invoke(custom_prompt)
        
        model_end_time = time.time()
        model_duration = model_end_time - model_start_time
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        logger.info(f"Video analysis completed successfully. Model inference: {model_duration:.2f}s, Total: {total_duration:.2f}s")
        logger.info(f"Generated summary length: {len(summary)} characters")
        
        return summary
    except Exception as e:
        end_time = time.time()
        duration = end_time - start_time
        logger.error(f"Error during video analysis after {duration:.2f}s: {str(e)}")
        st.error(f"Error during video analysis: {str(e)}")
        return f"Error: Could not analyze video - {str(e)}"

# Main Application UI
st.title("üìπ Video Summarization App")

# Create tabs for different functionality
tab1, tab2, tab3 = st.tabs(["üìπ Video Processor", "üìä Analytics", "üîÑ Batch Processing"])

with tab1:
    # Enhanced upload experience
    st.subheader("Upload Video")
    
    # Batch processing toggle
    batch_mode = st.checkbox("üîÑ Batch Processing Mode")
    
    if not batch_mode:
        uploaded_file = st.file_uploader(
            "Upload Video",
            type=["mp4", "avi", "mov", "mkv"],
            accept_multiple_files=False,
            help="Maximum file size: 200MB. Supported formats: MP4, AVI, MOV, MKV"
        )

        if uploaded_file:
            # Display file information
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("File Size", f"{uploaded_file.size / (1024*1024):.1f} MB")
            with col2:
                st.metric("File Type", uploaded_file.type)
            with col3:
                file_display_name = uploaded_file.name[:20] + "..." if len(uploaded_file.name) > 20 else uploaded_file.name
                st.metric("File Name", file_display_name)
            
            logger.info(f"Processing uploaded file: {uploaded_file.name} ({uploaded_file.size} bytes)")
            overall_start_time = time.time()
            
            try:
                file_path = upload_video(uploaded_file)
                extract_frames(file_path, interval_seconds)
                summary = describe_video()
                
                if summary and not summary.startswith("Error:"):
                    logger.info("Video processing completed successfully")
                    
                    # Enhanced summary display
                    st.markdown("## üìπ Video Summary")
                    
                    # Add summary statistics
                    col1, col2 = st.columns(2)
                    processing_time = time.time() - overall_start_time
                    with col1:
                        st.metric("Summary Length", f"{len(summary.split())} words")
                    with col2:
                        st.metric("Processing Time", f"{processing_time:.1f}s")
                    
                    # Enhanced summary display
                    st.markdown("### Content Analysis")
                    st.markdown(f"> {summary}")
                    
                    # Export and action buttons
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        report = export_summary(summary, uploaded_file.name, processing_time, selected_model)
                        st.download_button(
                            "üìÑ Download Report",
                            report,
                            file_name=f"summary_{uploaded_file.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                            mime="text/markdown"
                        )
                    
                    with col2:
                        if st.button("üìã Copy to Clipboard"):
                            st.success("Summary copied to clipboard!")
                            st.code(summary, language=None)
                    
                    with col3:
                        if st.button("üîÑ Regenerate"):
                            st.rerun()
                    
                    # Save processing history
                    save_processing_history(uploaded_file.name, summary, processing_time, selected_model)
                    
                    # Display extracted frames
                    display_extracted_frames()
                else:
                    logger.error("Failed to generate video summary")
                    st.error("Failed to generate video summary")
                    
            except Exception as e:
                logger.error(f"Unexpected error during video processing: {str(e)}")
                st.error(f"An error occurred: {str(e)}")
                st.info("Please try with a different video file")
            finally:
                overall_end_time = time.time()
                total_duration = overall_end_time - overall_start_time
                logger.info(f"Total processing time: {total_duration:.2f} seconds")
                logger.info("-" * 50)  # Separator for log readability
    
    else:
        # Batch processing mode
        st.subheader("üîÑ Batch Processing")
        uploaded_files = st.file_uploader(
            "Upload Multiple Videos",
            type=["mp4", "avi", "mov", "mkv"],
            accept_multiple_files=True,
            help="Select multiple videos for batch processing"
        )
        
        if uploaded_files and st.button("Process All Videos"):
            results = []
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for i, file in enumerate(uploaded_files):
                status_text.text(f"Processing {file.name}... ({i+1}/{len(uploaded_files)})")
                
                try:
                    file_path = upload_video(file)
                    extract_frames(file_path, interval_seconds)
                    summary = describe_video()
                    
                    if summary and not summary.startswith("Error:"):
                        results.append({
                            'filename': file.name,
                            'summary': summary,
                            'status': 'Success'
                        })
                        # Save to history
                        save_processing_history(file.name, summary, 0, selected_model)
                    else:
                        results.append({
                            'filename': file.name,
                            'summary': summary,
                            'status': 'Failed'
                        })
                except Exception as e:
                    results.append({
                        'filename': file.name,
                        'summary': f"Error: {str(e)}",
                        'status': 'Error'
                    })
                
                progress_bar.progress((i + 1) / len(uploaded_files))
            
            status_text.text("Batch processing completed!")
            
            # Display batch results
            st.markdown("## Batch Processing Results")
            for result in results:
                status_emoji = "‚úÖ" if result['status'] == 'Success' else "‚ùå"
                with st.expander(f"{status_emoji} {result['filename']}"):
                    st.write(f"**Status:** {result['status']}")
                    st.write(f"**Summary:** {result['summary']}")

with tab2:
    st.markdown("## üìä Processing Analytics")
    
    if os.path.exists("processing_history.json"):
        with open("processing_history.json", 'r') as f:
            history = json.load(f)
        
        if history:
            # Create analytics
            processing_times = [entry['processing_time'] for entry in history]
            dates = [entry['timestamp'][:10] for entry in history]
            models_used = [entry.get('model_used', 'Unknown') for entry in history]
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("Total Videos Processed", len(history))
                st.metric("Average Processing Time", f"{sum(processing_times)/len(processing_times):.1f}s")
            
            with col2:
                st.metric("Fastest Processing", f"{min(processing_times):.1f}s")
                st.metric("Slowest Processing", f"{max(processing_times):.1f}s")
            
            # Display recent processing history
            st.subheader("Recent Processing History")
            for entry in reversed(history[-10:]):  # Show last 10
                with st.expander(f"{entry['video_name']} - {entry['timestamp'][:10]}"):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Processing Time:** {entry['processing_time']:.1f}s")
                        st.write(f"**Model Used:** {entry.get('model_used', 'N/A')}")
                    with col2:
                        st.write(f"**Date:** {entry['timestamp']}")
                    st.write(f"**Summary:** {entry['summary']}")
        else:
            st.info("No processing history available yet.")
    else:
        st.info("No processing history file found.")

with tab3:
    st.markdown("## üîÑ Batch Processing")
    st.info("Use the batch processing mode in the Video Processor tab to process multiple videos at once.")
    
    # Show batch processing instructions
    st.markdown("""
    ### How to use Batch Processing:
    1. Go to the **Video Processor** tab
    2. Enable **Batch Processing Mode**
    3. Upload multiple video files
    4. Click **Process All Videos**
    5. View results for each video
    """)


